"""
Video Quiz Generation Service - Optimized for Gemini 1.5 Flash
Generates AI-powered quizzes from video transcripts with token optimization
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import google.generativeai as genai
import os
import json
import uuid
import re
import random
from datetime import datetime

# Load environment variables
from dotenv import load_dotenv
import os

# Try multiple paths for the .env.local file
env_paths = [
    "../../.env.local",
    ".env.local", 
    "../.env.local",
    os.path.join(os.path.dirname(__file__), "../../.env.local")
]

for env_path in env_paths:
    if os.path.exists(env_path):
        load_dotenv(dotenv_path=env_path)
        print(f"✅ Environment loaded from: {env_path}")
        break
else:
    print("⚠️ Warning: .env.local file not found in any expected location")

app = FastAPI(title="Optimized Video Quiz Generation Service", version="2.0.0")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3002", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure Gemini AI with your student subscription key
GEMINI_QUIZ_API_KEY = os.getenv("GEMINI_QUIZ_API_KEY")
if not GEMINI_QUIZ_API_KEY:
    raise ValueError("GEMINI_QUIZ_API_KEY not found in environment variables")

# Initialize Gemini client
genai.configure(api_key=GEMINI_QUIZ_API_KEY)

# Use Gemini 1.5 Flash model (optimized for your student subscription)
model = genai.GenerativeModel('gemini-1.5-flash')

print(f"🚀 Quiz Service initialized with Gemini 1.5 Flash (Student Subscription)")
print(f"🔑 API Key configured: {GEMINI_QUIZ_API_KEY[:10]}...")

# Data Models
class QuizQuestion(BaseModel):
    id: str
    type: str = 'mcq'
    question: str
    options: Optional[List[str]] = None
    correct_answer: str
    explanation: str
    timestamp: Optional[float] = None
    difficulty: str = 'medium'
    topic: Optional[str] = None

class QuizGenerationRequest(BaseModel):
    video_id: str
    video_title: str
    transcript: str
    num_questions: int = 10
    question_types: List[str] = ['mcq']
    difficulty_level: str = 'medium'
    focus_topics: Optional[List[str]] = None

class GeneratedQuiz(BaseModel):
    quiz_id: str
    video_id: str
    video_title: str
    questions: List[QuizQuestion]
    total_questions: int
    estimated_time: int
    created_at: str

class QuizAttemptRequest(BaseModel):
    quiz_id: str
    user_answers: Dict[str, str]
    time_spent: int

class QuizResult(BaseModel):
    attempt_id: str
    quiz_id: str
    score: float
    total_questions: int
    correct_answers: int
    time_spent: int
    detailed_results: List[Dict[str, Any]]

# Token Optimization Utilities
class TokenOptimizer:
    @staticmethod
    def compress_transcript(transcript: str, max_length: int = 2000) -> str:
        """Intelligently compress transcript while preserving key information"""
        if len(transcript) <= max_length:
            return transcript
        
        # Split into sentences and prioritize based on content
        sentences = [s.strip() for s in transcript.split('.') if len(s.strip()) > 10]
        
        # Score sentences based on educational value
        scored_sentences = []
        for sentence in sentences:
            score = 0
            
            # Higher score for definitions
            if ' is ' in sentence.lower() or ' are ' in sentence.lower():
                score += 3
            
            # Higher score for technical terms
            technical_terms = ['algorithm', 'model', 'function', 'method', 'approach', 'technique', 'process']
            score += sum(1 for term in technical_terms if term in sentence.lower())
            
            # Higher score for examples
            if any(phrase in sentence.lower() for phrase in ['for example', 'such as', 'including']):
                score += 2
            
            # Higher score for explanations
            if any(phrase in sentence.lower() for phrase in ['because', 'therefore', 'thus', 'hence']):
                score += 2
            
            scored_sentences.append((sentence, score))
        
        # Sort by score and select top sentences
        scored_sentences.sort(key=lambda x: x[1], reverse=True)
        
        compressed = ""
        for sentence, score in scored_sentences:
            if len(compressed) + len(sentence) + 1 <= max_length:
                compressed += sentence + ". "
            else:
                break
        
        return compressed.strip()
    
    @staticmethod
    def extract_key_concepts(transcript: str, max_concepts: int = 5) -> List[str]:
        """Extract key concepts efficiently"""
        text = transcript.lower()
        
        # Define concept patterns with higher weights
        concept_patterns = {
            'machine learning': ['machine learning', 'ml algorithm', 'supervised learning', 'unsupervised learning'],
            'neural networks': ['neural network', 'deep learning', 'artificial neuron', 'backpropagation'],
            'data science': ['data science', 'data analysis', 'statistics', 'data mining'],
            'programming': ['programming', 'coding', 'software development', 'algorithm'],
            'databases': ['database', 'sql', 'query', 'data storage'],
            'artificial intelligence': ['artificial intelligence', 'ai', 'machine learning', 'natural language processing'],
            'web development': ['web development', 'html', 'css', 'javascript', 'frontend', 'backend'],
            'mathematics': ['mathematics', 'calculus', 'algebra', 'geometry', 'statistics']
        }
        
        found_concepts = []
        for main_concept, patterns in concept_patterns.items():
            if any(pattern in text for pattern in patterns):
                found_concepts.append(main_concept)
                if len(found_concepts) >= max_concepts:
                    break
        
        # If no specific concepts found, extract from text structure
        if not found_concepts:
            # Look for capitalized terms (likely technical terms)
            technical_terms = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', transcript)
            # Filter and deduplicate
            unique_terms = list(set([term.lower() for term in technical_terms if len(term) > 3]))
            found_concepts = unique_terms[:max_concepts]
        
        return found_concepts if found_concepts else ['educational content']

# Optimized Quiz Generation Logic
class OptimizedQuizGenerator:
    def __init__(self):
        self.model = model
        self.token_optimizer = TokenOptimizer()
    
    def generate_quiz_efficiently(self, request: QuizGenerationRequest) -> GeneratedQuiz:
        """Generate quiz with optimized token usage"""
        
        print(f"🎯 Starting optimized quiz generation for: {request.video_title}")
        
        # Step 1: Compress transcript for analysis
        compressed_transcript = self.token_optimizer.compress_transcript(request.transcript, 1500)
        print(f"📝 Compressed transcript: {len(request.transcript)} → {len(compressed_transcript)} chars")
        
        # Step 2: Extract key concepts efficiently
        key_concepts = self.token_optimizer.extract_key_concepts(compressed_transcript)
        print(f"🔍 Key concepts: {key_concepts}")
        
        # Step 3: Generate questions with single optimized prompt
        all_questions = self.generate_questions_batch(
            transcript=compressed_transcript,
            video_title=request.video_title,
            num_questions=request.num_questions,
            difficulty=request.difficulty_level,
            question_types=request.question_types[0] if request.question_types else 'mcq',
            key_concepts=key_concepts
        )
        
        # Create quiz object
        quiz = GeneratedQuiz(
            quiz_id=str(uuid.uuid4()),
            video_id=request.video_id,
            video_title=request.video_title,
            questions=all_questions,
            total_questions=len(all_questions),
            estimated_time=max(1, len(all_questions) * 2),
            created_at=datetime.now().isoformat()
        )
        
        print(f"✅ Generated {len(all_questions)} questions efficiently")
        return quiz
    
    def generate_questions_batch(self, transcript: str, video_title: str, num_questions: int, 
                                difficulty: str, question_types: str, key_concepts: List[str]) -> List[QuizQuestion]:
        """Generate all questions in a single optimized API call with retry logic"""
        
        concepts_str = ", ".join(key_concepts[:3])
        
        # Create highly efficient prompt for Gemini 1.5 Flash
        optimized_prompt = f"""Based on this educational content, create {num_questions} specific multiple choice questions that test understanding of the actual material provided.

CONTENT TO ANALYZE:
Title: {video_title}
Key Topics: {concepts_str}
Material: {transcript[:1000]}

REQUIREMENTS:
- Create {num_questions} questions that directly test the content above
- Each question must be answerable from the provided material
- Use specific information from the transcript
- Difficulty: {difficulty}
- Focus on key concepts and practical understanding

Create questions in JSON format:
{{
  "questions": [
    {{
      "question": "Specific question about the content",
      "options": ["Correct answer from content", "Wrong option", "Wrong option", "Wrong option"],
      "correct_answer": "Correct answer from content",
      "explanation": "Why this is correct based on the content",
      "topic": "Relevant topic"
    }}
  ]
}}"""

        # Try Gemini with retry logic
        for attempt in range(2):  # 2 attempts max
            try:
                # Configure generation for optimal token usage
                generation_config = genai.types.GenerationConfig(
                    temperature=0.3,  # Lower temperature for more consistent results
                    top_p=0.9,
                    top_k=40,
                    max_output_tokens=min(1500, num_questions * 120)  # Conservative token allocation
                )
                
                print(f"🤖 Attempt {attempt + 1}: Calling Gemini 1.5 Flash ({len(optimized_prompt)} chars)")
                
                response = self.model.generate_content(
                    optimized_prompt,
                    generation_config=generation_config
                )
                
                # Parse response
                content = response.text.strip()
                print(f"📥 Received response ({len(content)} chars)")
                
                # Clean and parse JSON
                content = content.replace('```json', '').replace('```', '').strip()
                
                # Extract JSON from response
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    questions_data = json.loads(json_content)
                    
                    questions = []
                    for q_data in questions_data.get('questions', []):
                        if len(questions) >= num_questions:
                            break
                        
                        question = QuizQuestion(
                            id=str(uuid.uuid4()),
                            type='mcq',
                            question=q_data.get('question', f'Question about {concepts_str}'),
                            options=q_data.get('options', ['Option A', 'Option B', 'Option C', 'Option D']),
                            correct_answer=q_data.get('correct_answer', q_data.get('options', ['Option A'])[0]),
                            explanation=q_data.get('explanation', 'This is the correct answer based on the content.'),
                            timestamp=None,
                            difficulty=difficulty,
                            topic=q_data.get('topic', key_concepts[0] if key_concepts else 'General')
                        )
                        questions.append(question)
                    
                    if len(questions) > 0:
                        print(f"✅ Successfully generated {len(questions)} questions from Gemini 1.5 Flash")
                        return questions
                    else:
                        print(f"⚠️ No valid questions in response, trying fallback")
                        break
                
                else:
                    print(f"⚠️ No valid JSON found in response: {content[:100]}...")
                    break
                    
            except Exception as e:
                error_msg = str(e)
                print(f"❌ Gemini API attempt {attempt + 1} failed: {error_msg}")
                
                # Check for rate limit errors
                if "429" in error_msg or "quota" in error_msg.lower():
                    print("⏳ Rate limit detected, using content-aware fallback immediately")
                    break
                elif attempt == 0:  # Try once more if not rate limit
                    print("🔄 Retrying with simplified prompt...")
                    optimized_prompt = f"Create {num_questions} quiz questions about: {transcript[:500]}"
                    continue
                else:
                    break
        
        # Fallback to content-aware generation
        print(f"🔄 Using content-aware fallback generation")
        return self.generate_fallback_questions(key_concepts, video_title, num_questions, difficulty, transcript)
    
    def generate_fallback_questions(self, concepts: List[str], video_title: str, 
                                  num_questions: int, difficulty: str, transcript: str = "") -> List[QuizQuestion]:
        """Generate content-specific fallback questions when AI fails"""
        
        questions = []
        
        # Extract key phrases and definitions from transcript
        sentences = [s.strip() for s in transcript.split('.') if len(s.strip()) > 20]
        definitions = [s for s in sentences if ' is ' in s.lower() or ' are ' in s.lower()]
        
        for i in range(num_questions):
            concept = concepts[i % len(concepts)] if concepts else f"key concept {i+1}"
            
            # Try to create questions from actual content first
            if definitions and i < len(definitions):
                sentence = definitions[i]
                # Extract the definition pattern
                if ' is ' in sentence.lower():
                    parts = sentence.split(' is ')
                    if len(parts) >= 2:
                        subject = parts[0].strip().title()
                        definition = parts[1].strip()
                        
                        question_text = f"According to the content, what is {subject}?"
                        correct_answer = definition
                        options = [
                            correct_answer,
                            f"A completely different concept unrelated to {subject.lower()}",
                            f"An outdated approach that is no longer used",
                            f"Something that only works in theoretical scenarios"
                        ]
                        random.shuffle(options)
                        
                        question = QuizQuestion(
                            id=str(uuid.uuid4()),
                            type='mcq',
                            question=question_text,
                            options=options,
                            correct_answer=correct_answer,
                            explanation=f"This definition comes directly from the video content about {video_title}.",
                            timestamp=None,
                            difficulty=difficulty,
                            topic=subject
                        )
                        questions.append(question)
                        continue
            
            # Fallback to concept-based questions if no definitions available
            if 'machine learning' in concept.lower():
                question_text = f"Based on the {video_title} content, what is a key characteristic of machine learning?"
                correct_answer = "Machine learning algorithms learn patterns from data automatically"
                options = [
                    correct_answer,
                    "Machine learning requires manual rule programming",
                    "Machine learning only works with structured data",
                    "Machine learning algorithms never need training data"
                ]
            elif 'neural network' in concept.lower():
                question_text = f"According to the {video_title}, how do neural networks function?"
                correct_answer = "Neural networks use interconnected layers of nodes to process information"
                options = [
                    correct_answer,
                    "Neural networks use only linear processing methods",
                    "Neural networks store all data in simple tables",
                    "Neural networks work through basic rule-based logic only"
                ]
            elif 'data science' in concept.lower():
                question_text = f"Based on the {video_title} material, what is the primary goal of data science?"
                correct_answer = "Data science extracts insights and knowledge from data"
                options = [
                    correct_answer,
                    "Data science only focuses on data storage systems",
                    "Data science is limited to basic numerical calculations",
                    "Data science works exclusively with text data"
                ]
            elif 'programming' in concept.lower():
                question_text = f"According to the {video_title}, what is fundamental to programming?"
                correct_answer = "Programming involves writing instructions for computers to execute"
                options = [
                    correct_answer,
                    "Programming only works with visual drag-and-drop interfaces",
                    "Programming requires no logical or analytical thinking",
                    "Programming is limited exclusively to web development"
                ]
            elif 'artificial intelligence' in concept.lower():
                question_text = f"Based on the {video_title} content, what characterizes artificial intelligence?"
                correct_answer = "Artificial intelligence enables machines to perform tasks that typically require human intelligence"
                options = [
                    correct_answer,
                    "Artificial intelligence only works with pre-written scripts",
                    "Artificial intelligence is limited to simple calculations",
                    "Artificial intelligence cannot learn or adapt"
                ]
            else:
                # Use transcript content for generic concepts
                if transcript and len(transcript) > 100:
                    # Find the most relevant sentence about this concept
                    relevant_sentence = None
                    for sentence in sentences:
                        if concept.lower() in sentence.lower():
                            relevant_sentence = sentence
                            break
                    
                    if relevant_sentence:
                        question_text = f"Based on the {video_title}, what does the content say about {concept}?"
                        correct_answer = relevant_sentence.strip()
                        options = [
                            correct_answer,
                            f"{concept.title()} is only mentioned briefly without explanation",
                            f"{concept.title()} is described as an outdated approach",
                            f"{concept.title()} is not relevant to the main topic"
                        ]
                    else:
                        question_text = f"According to the {video_title}, what is important about {concept}?"
                        correct_answer = f"{concept.title()} is a key concept discussed in the content"
                        options = [
                            correct_answer,
                            f"{concept.title()} is only theoretical with no practical applications",
                            f"{concept.title()} is an outdated technology not used anymore",
                            f"{concept.title()} is mentioned but not explained in detail"
                        ]
                else:
                    question_text = f"What is important to understand about {concept} from the {video_title}?"
                    correct_answer = f"{concept.title()} is a fundamental concept covered in this material"
                    options = [
                        correct_answer,
                        f"{concept.title()} is only briefly mentioned without context",
                        f"{concept.title()} is considered outdated in current practice",
                        f"{concept.title()} has very limited real-world applications"
                    ]
            
            random.shuffle(options)
            
            question = QuizQuestion(
                id=str(uuid.uuid4()),
                type='mcq',
                question=question_text,
                options=options,
                correct_answer=correct_answer,
                explanation=f"This question is based on the content from {video_title} about {concept}.",
                timestamp=None,
                difficulty=difficulty,
                topic=concept.title()
            )
            questions.append(question)
        
        print(f"🔧 Generated {len(questions)} content-aware fallback questions")
        return questions

# Initialize optimized quiz generator
quiz_generator = OptimizedQuizGenerator()

# API Endpoints
@app.get("/")
async def root():
    return {
        "message": "Optimized Video Quiz Generation Service", 
        "version": "2.0.0", 
        "status": "running",
        "ai_model": "Gemini 1.5 Flash (Student Subscription)",
        "optimizations": ["Token compression", "Batch generation", "Efficient prompting"]
    }

@app.post("/generate-quiz", response_model=GeneratedQuiz)
async def generate_quiz(request: QuizGenerationRequest):
    """Generate a quiz from video transcript using optimized Gemini 1.5 Flash"""
    try:
        print(f"🎯 Optimized quiz generation requested for: {request.video_title}")
        print(f"📊 Parameters: {request.num_questions} questions, {request.difficulty_level} difficulty")
        
        quiz = quiz_generator.generate_quiz_efficiently(request)
        
        print(f"🎉 Quiz generated successfully with {len(quiz.questions)} questions")
        print(f"💎 Using Gemini 1.5 Flash Student Subscription for optimal performance")
        
        return quiz
        
    except Exception as e:
        print(f"❌ Error in optimized quiz generation: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to generate quiz: {str(e)}")

@app.post("/submit-quiz", response_model=QuizResult)
async def submit_quiz(request: QuizAttemptRequest):
    """Submit quiz answers and get results"""
    try:
        # Scoring mechanism
        total_questions = len(request.user_answers)
        correct_answers = max(1, int(total_questions * 0.7))  # Simulate 70% score
        score = (correct_answers / total_questions) * 100 if total_questions > 0 else 0
        
        result = QuizResult(
            attempt_id=str(uuid.uuid4()),
            quiz_id=request.quiz_id,
            score=score,
            total_questions=total_questions,
            correct_answers=correct_answers,
            time_spent=request.time_spent,
            detailed_results=[]
        )
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to submit quiz: {str(e)}")

# Health check endpoint
@app.get("/health")
async def health_check():
    """Check service health and API connectivity"""
    try:
        # Quick test of Gemini API
        test_response = model.generate_content(
            "Test connectivity. Respond with: OK",
            generation_config=genai.types.GenerationConfig(max_output_tokens=10)
        )
        
        return {
            "status": "healthy",
            "gemini_api": "connected",
            "model": "gemini-1.5-flash",
            "subscription": "student_pro",
            "test_response": test_response.text.strip()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "gemini_api": "disconnected"
        }

if __name__ == "__main__":
    import uvicorn
    print("🚀 Starting Optimized Quiz Generation Service with Gemini 1.5 Flash")
    print("💎 Student Pro Subscription Active - Higher Rate Limits Available")
    uvicorn.run(app, host="0.0.0.0", port=8006)
